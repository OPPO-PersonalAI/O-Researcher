# =============================================================================
#                         O-Researcher 统一配置文件
# =============================================================================
# 使用方法: 
#   1. 复制此文件为 .env:  cp env_template .env
#   2. 编辑 .env 填写实际值
#   3. 注意：.env 文件不要提交到 git
# =============================================================================


# =============================================================================
# 服务器配置 (server/start_servers.sh)
# =============================================================================

export SERVER_HOST="127.0.0.1"          # 服务监听地址
export CRAWL_PAGE_PORT="20001"          # CrawlPage 服务端口
export WEBSEARCH_PORT="20002"           # WebSearch 服务端口
export CRAWL_PAGE_WORKERS=10            # CrawlPage worker 进程数
export WEBSEARCH_WORKERS=10             # WebSearch worker 进程数


# =============================================================================
# API 配置
# =============================================================================

export SUMMARY_API_URLS="https://your-api-url.com/v1"   # API 地址（多个用 | 分隔）
export SUMMARY_OPENAI_API_KEY="sk-your-api-key"         # OpenAI API Key
export SUMMARY_MODEL="gpt-5-mini"                            # 使用的模型名称
export SERP_API_KEY="your-serp-api-key"                 # Serper API Key
export JINA_API_KEY="your-jina-api-key"                 # Jina API Key


# =============================================================================
# 模型部署配置 (deploy/deploy.sh)
# =============================================================================

export MODEL_PATH="/path/to/your/model"     # 模型路径（必填）
export MODEL_NAME="your_model_name"         # 模型名称（必填）
export MODEL_BASE_PORT="9095"               # 模型服务基础端口
export DEPLOY_HOST="0.0.0.0"                # 部署服务监听地址

# 部署参数（可选，有默认值）
export DEPLOY_INSTANCES=1                   # 部署实例数
export DEPLOY_GPUS_PER_INSTANCE=4           # 每个实例使用的 GPU 数
export DEPLOY_MAX_MODEL_LEN=131072          # 最大模型长度
export DEPLOY_WAIT_TIMEOUT=300              # 启动超时时间（秒）
export DEPLOY_LOG_DIR="deploy/logs"         # 部署日志目录

# =============================================================================
# 推理配置 (infer/infer.py)
# =============================================================================

# 模型 API 地址（多实例用 | 分隔，自动轮询负载均衡）
# 注意：如果 DEPLOY_INSTANCES > 1，需要配置多个端口
#       端口从 MODEL_BASE_PORT 开始递增
#       例如：DEPLOY_INSTANCES=2, MODEL_BASE_PORT=9095 → 端口为 9095, 9096
#
# 单实例示例（DEPLOY_INSTANCES=1）：
export MODEL_URL="http://localhost:9095/v1"
# 双实例示例（DEPLOY_INSTANCES=2）：
# export MODEL_URL="http://localhost:9095/v1|http://localhost:9096/v1"
# 三实例示例（DEPLOY_INSTANCES=3）：
# export MODEL_URL="http://localhost:9095/v1|http://localhost:9096/v1|http://localhost:9097/v1"

# 工具服务地址
export WEBSEARCH_URL="http://localhost:20002/search"
export CRAWL_PAGE_URL="http://localhost:20001/crawl_page"

# =============================================================================
# 系统优化（可选）
# =============================================================================

export OMP_NUM_THREADS=16                  # OpenMP 线程数
export TORCHDYNAMO_VERBOSE=1               # TorchDynamo 调试输出
export VLLM_USE_V1=1                       # 使用 vLLM v1 版本
